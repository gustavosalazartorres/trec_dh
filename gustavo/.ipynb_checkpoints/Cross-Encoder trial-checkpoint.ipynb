{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1bdc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.cross_encoder import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194ea515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b81755e21dc451f9d0335d1eb853605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)055d2/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d35cf5795f45708e9e05fd21a743c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3691f055d2/README.md:   0%|          | 0.00/13.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648f46eee258490f9c57076ed66fb828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)91f055d2/config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dd54097b6e44239216c78fb70cc456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570ad6e7a4ec4c2fa753d4596458cd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c4cfd57234c00afa15f7f3bed16e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)055d2/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd9d10deb4640d2a0f0ba2b82294e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/g.salazar.2/.cache/torch/sentence_transformers/EleutherAI_pythia-70m. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /Users/g.salazar.2/.cache/torch/sentence_transformers/EleutherAI_pythia-70m were not used when initializing GPTNeoXModel: ['embed_out.weight']\n",
      "- This IS expected if you are initializing GPTNeoXModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('EleutherAI/pythia-70m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22054011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25aef666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, IterableDataset\n",
    "\n",
    "class PairDataset:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.examples = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        print(\"open\", self.filepath)\n",
    "        with gzip.open(self.filepath, 'rt') as fIn:\n",
    "            for line in fIn:\n",
    "                example = self.get_example(json.loads(line))\n",
    "                if example is not None:\n",
    "                    self.examples.append(example)\n",
    "                    yield example\n",
    "\n",
    "        while True:\n",
    "            random.shuffle(self.examples)\n",
    "            for ex in self.examples:\n",
    "                yield ex\n",
    "                \n",
    "    def get_example(self, raw_example):\n",
    "        if isinstance(raw_example, dict):\n",
    "            return InputExample(texts=[raw_example['query'], random.choice(raw_example['pos'])], label=1)\n",
    "        else:\n",
    "            return InputExample(texts=[raw_example[0], raw_example[1]], label=1)\n",
    "\n",
    "\n",
    "class RedditTitleDataset(PairDataset):\n",
    "    def get_example(self, raw_example):\n",
    "        return [self.clean_title(raw_example['title']), raw_example['body']]\n",
    "\n",
    "\n",
    "    def clean_title(self, text):\n",
    "        text = text.replace(\"&amp;\", \"&\").strip()\n",
    "        if text.startswith(\"[\"):\n",
    "            text = re.sub(\"^\\[[a-zA-Z0-9]+\\]\", \"\", text).strip()\n",
    "\n",
    "        if text.endswith(\"]\"):\n",
    "            text = re.sub(\"\\[[a-zA-Z0-9\\.]+\\]$\", \"\", text).strip()\n",
    "\n",
    "        if text.startswith(\"/r\"):\n",
    "            text = re.sub(\"^/[a-zA-Z0-9/]+[;,: \\-]+\", \"\", text).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "class StackExchangeTitleBodyDataset(PairDataset):\n",
    "    def get_example(self, raw_example):\n",
    "        return raw_example['texts']\n",
    "\n",
    "\n",
    "class MultiDataset(IterableDataset):\n",
    "    def __init__(self, filepaths, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "        self.datasets = []\n",
    "        self.data_iterators = []\n",
    "\n",
    "        for filepath in filepaths:\n",
    "            if 'reddit_title_text' in filepath:\n",
    "                dataset = RedditTitleDataset(filepath)\n",
    "            elif 'stackexchange_archive/jsonl' in filepath:\n",
    "                dataset = StackExchangeTitleBodyDataset(filepath)\n",
    "            else:\n",
    "                dataset = PairDataset(filepath)\n",
    "            self.datasets.append(dataset)\n",
    "            self.data_iterators.append(iter(dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            for dataset in self.data_iterators:\n",
    "                yield next(dataset)\n",
    "\n",
    "            random.shuffle(self.data_iterators)\n",
    "\n",
    "    def delete_examples_cache(self):\n",
    "        for dataset in self.datasets:\n",
    "            dataset.examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ee2c70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlong\u001b[49m(random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'long' is not defined"
     ]
    }
   ],
   "source": [
    "long(random.randint(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6cccef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "def get_example(raw_example):\n",
    "    if isinstance(raw_example, dict):\n",
    "        return InputExample(texts=[raw_example['query'], random.choice(raw_example['pos'])], label=random.randint(0, 3))\n",
    "    else:\n",
    "        return InputExample(texts=[raw_example[0], raw_example[1]], label=random.randint(0, 3))\n",
    "        \n",
    "def load_pair_dataset(filepath):\n",
    "    examples=[]\n",
    "    with gzip.open(filepath, 'rt') as fIn:\n",
    "            for line in fIn:\n",
    "                example = get_example(json.loads(line))\n",
    "                examples.append(example)\n",
    "    return examples\n",
    "\n",
    "full_set = load_pair_dataset(\"/Users/g.salazar.2/git/trec_dh/gustavo/gooaq_pairs.jsonl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c717b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3012496"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "004d11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(train_set, test_set) = train_test_split(full_set, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff3dc7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018372, 994124)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c433cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/pythia-70m were not used when initializing GPTNeoXForSequenceClassification: ['embed_out.weight']\n",
      "- This IS expected if you are initializing GPTNeoXForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-70m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-04 03:04:36 - Use pytorch device: cpu\n",
      "2023-06-04 03:04:36 - Warmup-steps: 50460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282a951ee39d4eb7b0448a6d6b783b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370a3c9fd2fc41c39222731f1e5271d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/504593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-04 03:05:45 - CERerankingEvaluator: Evaluating the model on train-eval dataset in epoch 0 after 100 steps:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'InputExample' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m          \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m          \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m          \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m          \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_saved\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:221\u001b[0m, in \u001b[0;36mCrossEncoder.fit\u001b[0;34m(self, train_dataloader, evaluator, epochs, loss_fct, activation_fct, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar)\u001b[0m\n\u001b[1;32m    218\u001b[0m training_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m evaluation_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m training_steps \u001b[38;5;241m%\u001b[39m evaluation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_during_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:299\u001b[0m, in \u001b[0;36mCrossEncoder._eval_during_training\u001b[0;34m(self, evaluator, output_path, save_best_model, epoch, steps, callback)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m\"\"\"Runs evaluation during the training\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m         callback(score, epoch, steps)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sentence_transformers/cross_encoder/evaluation/CERerankingEvaluator.py:46\u001b[0m, in \u001b[0;36mCERerankingEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     44\u001b[0m num_negatives \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples:\n\u001b[0;32m---> 46\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     47\u001b[0m     positive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     48\u001b[0m     negative \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'InputExample' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "import math\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "import torch.nn\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "train_batch_size = 4\n",
    "num_epochs = 1\n",
    "num_labels = 4\n",
    "max_length = 512\n",
    "evaluation_steps = 100\n",
    "lr = 7e-6\n",
    "\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=train_batch_size)\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "default_activation_function = torch.nn.Identity()\n",
    "\n",
    "model = CrossEncoder('EleutherAI/pythia-70m', num_labels=num_labels, \n",
    "                     tokenizer_args={'pad_token': '[PAD]'}, \n",
    "                     default_activation_function=default_activation_function)\n",
    "# evaluator = CEBinaryClassificationEvaluator.from_input_examples(test_set, name='trec-ev')\n",
    "evaluator = CERerankingEvaluator(test_set, name='train-eval')\n",
    "\n",
    "# Configure the training\n",
    "\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "loss_fct=torch.nn.L1Loss()\n",
    "\n",
    "model.config.pad_token_id = model.tokenizer.pad_token_id\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,\n",
    "          optimizer_params={'lr': lr},\n",
    "          output_path=\"model_saved\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
